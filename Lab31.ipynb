{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "c336e45c-b318-4a43-90bc-7f1e78c8c88a",
      "metadata": {},
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'numpy'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'numpy'"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "41883f98",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 2s 0us/step\n",
            "Epoch 1/50\n",
            "235/235 [==============================] - 4s 12ms/step - loss: 0.2762 - val_loss: 0.1894\n",
            "Epoch 2/50\n",
            "235/235 [==============================] - 2s 10ms/step - loss: 0.1705 - val_loss: 0.1533\n",
            "Epoch 3/50\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.1440 - val_loss: 0.1329\n",
            "Epoch 4/50\n",
            "235/235 [==============================] - 2s 10ms/step - loss: 0.1277 - val_loss: 0.1204\n",
            "Epoch 5/50\n",
            "235/235 [==============================] - 2s 10ms/step - loss: 0.1178 - val_loss: 0.1126\n",
            "Epoch 6/50\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.1112 - val_loss: 0.1073\n",
            "Epoch 7/50\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.1065 - val_loss: 0.1031\n",
            "Epoch 8/50\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 0.1029 - val_loss: 0.1000\n",
            "Epoch 9/50\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1001 - val_loss: 0.0978\n",
            "Epoch 10/50\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.0980 - val_loss: 0.0957\n",
            "Epoch 11/50\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.0965 - val_loss: 0.0945\n",
            "Epoch 12/50\n",
            "235/235 [==============================] - 2s 10ms/step - loss: 0.0955 - val_loss: 0.0939\n",
            "Epoch 13/50\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.0950 - val_loss: 0.0933\n",
            "Epoch 14/50\n",
            "235/235 [==============================] - 2s 11ms/step - loss: 0.0945 - val_loss: 0.0929\n",
            "Epoch 15/50\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.0942 - val_loss: 0.0927\n",
            "Epoch 16/50\n",
            "235/235 [==============================] - 2s 10ms/step - loss: 0.0940 - val_loss: 0.0927\n",
            "Epoch 17/50\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 0.0938 - val_loss: 0.0924\n",
            "Epoch 18/50\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 0.0937 - val_loss: 0.0922\n",
            "Epoch 19/50\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.0935 - val_loss: 0.0922\n",
            "Epoch 20/50\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.0934 - val_loss: 0.0921\n",
            "Epoch 21/50\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.0934 - val_loss: 0.0920\n",
            "Epoch 22/50\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.0933 - val_loss: 0.0920\n",
            "Epoch 23/50\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.0932 - val_loss: 0.0919\n",
            "Epoch 24/50\n",
            "235/235 [==============================] - 2s 10ms/step - loss: 0.0932 - val_loss: 0.0919\n",
            "Epoch 25/50\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.0931 - val_loss: 0.0919\n",
            "Epoch 26/50\n",
            "235/235 [==============================] - 2s 11ms/step - loss: 0.0931 - val_loss: 0.0919\n",
            "Epoch 27/50\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.0930 - val_loss: 0.0918\n",
            "Epoch 28/50\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.0930 - val_loss: 0.0918\n",
            "Epoch 29/50\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.0930 - val_loss: 0.0919\n",
            "Epoch 30/50\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.0929 - val_loss: 0.0918\n",
            "Epoch 31/50\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.0929 - val_loss: 0.0917\n",
            "Epoch 32/50\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.0929 - val_loss: 0.0917\n",
            "Epoch 33/50\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.0929 - val_loss: 0.0917\n",
            "Epoch 34/50\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.0929 - val_loss: 0.0918\n",
            "Epoch 35/50\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.0929 - val_loss: 0.0916\n",
            "Epoch 36/50\n",
            "235/235 [==============================] - 2s 10ms/step - loss: 0.0928 - val_loss: 0.0917\n",
            "Epoch 37/50\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.0928 - val_loss: 0.0916\n",
            "Epoch 38/50\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.0928 - val_loss: 0.0916\n",
            "Epoch 39/50\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.0928 - val_loss: 0.0916\n",
            "Epoch 40/50\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.0928 - val_loss: 0.0916\n",
            "Epoch 41/50\n",
            "235/235 [==============================] - 2s 11ms/step - loss: 0.0927 - val_loss: 0.0916\n",
            "Epoch 42/50\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.0927 - val_loss: 0.0916\n",
            "Epoch 43/50\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.0927 - val_loss: 0.0916\n",
            "Epoch 44/50\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.0927 - val_loss: 0.0915\n",
            "Epoch 45/50\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.0927 - val_loss: 0.0916\n",
            "Epoch 46/50\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.0927 - val_loss: 0.0915\n",
            "Epoch 47/50\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.0927 - val_loss: 0.0915\n",
            "Epoch 48/50\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.0927 - val_loss: 0.0915\n",
            "Epoch 49/50\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.0926 - val_loss: 0.0915\n",
            "Epoch 50/50\n",
            "235/235 [==============================] - 4s 17ms/step - loss: 0.0926 - val_loss: 0.0915\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.0915\n",
            "Test loss: 0.09151912480592728\n",
            "313/313 [==============================] - 2s 5ms/step\n"
          ]
        }
      ],
      "source": [
        "# Завантаження даних MNIST\n",
        "(x_train, _), (x_test, _) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "# Нормалізація даних\n",
        "x_train = x_train.astype('float32') / 255.\n",
        "x_test = x_test.astype('float32') / 255.\n",
        "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
        "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
        "\n",
        "# Розмірність кодувального простору\n",
        "encoding_dim = 32  # Задаємо розмірність кодованого представлення\n",
        "\n",
        "# Вхідне зображення\n",
        "input_img = Input(shape=(784,))\n",
        "\n",
        "# \"Закодована\" представлення\n",
        "encoded = Dense(encoding_dim, activation='relu')(input_img)\n",
        "\n",
        "# Відновлення вихідного зображення\n",
        "decoded = Dense(784, activation='sigmoid')(encoded)\n",
        "\n",
        "# Модель автокодувальника\n",
        "autoencoder = Model(input_img, decoded)\n",
        "\n",
        "# Компіляція моделі\n",
        "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "\n",
        "# Навчання автокодувальника\n",
        "autoencoder.fit(x_train, x_train,\n",
        "                epochs=50,\n",
        "                batch_size=256,\n",
        "                shuffle=True,\n",
        "                validation_data=(x_test, x_test))\n",
        "\n",
        "# Оцінка точності моделі на тестових даних\n",
        "score = autoencoder.evaluate(x_test, x_test)\n",
        "print('Test loss:', score)\n",
        "\n",
        "# Застосування автокодувальника для зображень\n",
        "decoded_imgs = autoencoder.predict(x_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "05398807",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Завантаження даних MNIST та попередня обробка\n",
        "(x_train, _), (x_test, _) = mnist.load_data()\n",
        "x_train = x_train.astype('float32') / 255.\n",
        "x_test = x_test.astype('float32') / 255.\n",
        "x_train = np.reshape(x_train, (len(x_train), 28, 28, 1))\n",
        "x_test = np.reshape(x_test, (len(x_test), 28, 28, 1))\n",
        "\n",
        "# Збудування згорткового автокодувальника\n",
        "input_img = Input(shape=(28, 28, 1))\n",
        "\n",
        "# Енкодер\n",
        "x = Conv2D(16, (3, 3), activation='relu', padding='same')(input_img)\n",
        "x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
        "x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
        "encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
        "\n",
        "# Декодер\n",
        "x = Conv2D(8, (3, 3), activation='relu', padding='same')(encoded)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "x = Conv2D(16, (3, 3), activation='relu')(x)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
        "\n",
        "# Створення моделі автокодувальника\n",
        "autoencoder = Model(input_img, decoded)\n",
        "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "\n",
        "# Навчання автокодувальника\n",
        "history = autoencoder.fit(x_train, x_train,\n",
        "                epochs=10,\n",
        "                batch_size=128,\n",
        "                shuffle=True,\n",
        "                validation_data=(x_test, x_test))\n",
        "\n",
        "# Графік функції втрат\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Побудова результуючих зображень\n",
        "decoded_imgs = autoencoder.predict(x_test)\n",
        "\n",
        "# Візуалізація результатів\n",
        "n = 10  # Кількість зображень, які ми хочемо показати\n",
        "plt.figure(figsize=(20, 4))\n",
        "for i in range(n):\n",
        "    # Вихідне зображення\n",
        "    ax = plt.subplot(2, n, i + 1)\n",
        "    plt.imshow(x_test[i].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "\n",
        "    # Відновлене зображення\n",
        "    ax = plt.subplot(2, n, i + 1 + n)\n",
        "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
